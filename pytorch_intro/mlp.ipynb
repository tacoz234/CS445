{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5f8ef0d-da8d-45d5-b9df-61419cbcd083",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b800f2cef036bd076150a659c36356a3",
     "grade": false,
     "grade_id": "cell-e03712c38ec8d498",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Implementing a Binary, Three-Layer NN in PyTorch\n",
    "\n",
    "Names and partners:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff033e9-1cf4-4449-98a3-f8f5b98cc821",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1266882e2490643e70049c6705e2071d",
     "grade": true,
     "grade_id": "name",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Cole Determan & Ben Berry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351cad85-57ab-4e98-82cd-60461a33fc02",
   "metadata": {},
   "source": [
    "First we'll create a dataset that is non-linearly seperable, and thus requires a hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513bdfec-b6fb-4ab6-813a-cadcbe557bfa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "594f6d86cd0b70ad3439e1f984a25ead",
     "grade": false,
     "grade_id": "cell-a02505c3caaf59f5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def noisy_xor(num_points):\n",
    "    \"\"\"Synthetic 2d Dataset that is not linearly separable.\"\"\"\n",
    "    features = np.random.randint(2, size=(num_points, 2))\n",
    "    labels = np.array(np.logical_xor(features[:, 0], features[:, 1]), dtype=np.float32)\n",
    "    labels = np.expand_dims(labels, 1)\n",
    "    features = np.array(\n",
    "        (features + (np.random.random(features.shape))) / 2.0,\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "train_size = 100\n",
    "X, y = noisy_xor(train_size)\n",
    "\n",
    "# Plot the dataset\n",
    "plt.plot(X[y[:, 0] == 1, 0], X[y[:, 0] == 1, 1], \"s\")\n",
    "plt.plot(X[y[:, 0] == 0, 0], X[y[:, 0] == 0, 1], \"o\")\n",
    "plt.show()\n",
    "\n",
    "# Convert to tensors\n",
    "X = torch.tensor(X)\n",
    "y = torch.tensor(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a709cb4-baba-4384-85f8-74d42a06b53d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ff44ddb6ac4c862142379a7fb6fe44e",
     "grade": false,
     "grade_id": "cell-9899e3ee5d67e347",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Neural Network Review\n",
    "\n",
    "Note: This cell may not be viewable in dark mode!\n",
    "\n",
    "Recall our illustration of a simple three-layer neural network:\n",
    "\n",
    "![Three Layer Network](nn_three.svg)\n",
    "\n",
    "The activation at the hidden layer can be expressed as:\n",
    "\n",
    "$h(\\mathbf{x}^\\textsf{T} \\mathbf{W}^{(1)} + \\mathbf{b}^{(1)})$\n",
    "\n",
    "In this example $h$ is the elementwise nonlinear function applied at the hidden layer, $\\mathbf{W}^{(1)}$ is a $4\\times 5$ weight matrix and $\\mathbf{b}^{(1)}$ is a $1\\times 5$ row vector containing the bias weights. (The bias weights are not shown in the image.)\n",
    "\n",
    "The final output of the network can be expressed as follows:\n",
    "\n",
    "$\\sigma\\left( \\color{gray} h(\\mathbf{x}^\\textsf{T} \\mathbf{W}^{(1)} + \\mathbf{b}^{(1)})\\color{black} \\mathbf{W}^{(2)} + b^{(2)}\\right)$\n",
    "\n",
    "Where $\\sigma$ is the logistic function, $\\mathbf{W}^{(2)}$ is a $5\\times 1$ weight matrix and $\\mathbf{b}^{(2)}$ is a scalar representing the bias weight of the output unit.\n",
    "\n",
    "Here are some utility functions for calculating the two non-linearities and the cross-entropy loss:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef987f34-a72e-4488-b9be-3a5a75c12d47",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd1a70a80010ec509376d365d66f0c57",
     "grade": false,
     "grade_id": "cell-fa0823df2c541385",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def binary_cross_entropy_loss(pred, labels):\n",
    "    return -torch.sum(labels * torch.log(pred) + (1.0 - labels) * torch.log(1.0 - pred))\n",
    "\n",
    "\n",
    "def logistic(a):\n",
    "    return 1.0 / (1.0 + torch.exp(-a))\n",
    "\n",
    "\n",
    "def relu(a):\n",
    "    return torch.max(a, torch.zeros_like(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0bdd07-d955-4f78-aa4c-fb9bb3e8873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW CREATE THE PARAMETERS FOR OUR NETWORK\n",
    "num_hidden = 10\n",
    "W1 = torch.randn((2, num_hidden), requires_grad=True)\n",
    "b1 = torch.randn((num_hidden,), requires_grad=True)\n",
    "W2 = torch.randn((num_hidden, 1), requires_grad=True)\n",
    "b2 = torch.randn((1,), requires_grad=True)\n",
    "\n",
    "params = [W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ad18d0-6b18-4ff3-9794-47f49c330047",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f16acad70e95673fd9714ce699926266",
     "grade": false,
     "grade_id": "cell-ef5cd002493592c6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Neural Network Implementation\n",
    "\n",
    "In the cell below, complete the unfinished `forward` function and add code to train the resulting network.  Some advice:\n",
    "* I suggest a nested training loop, where the out loop iterates over the epochs, and the inner loop iterates over the individual samples. For this simple implementation we'll perform a weight update after each sample. It is best practice to shuffle the data each epoch, but don't worry about that here.\n",
    "* Start with a learning rate around .01\n",
    "* It may take several hundred epochs to find a good fit.\n",
    "* You may want a helper method named someing like `opt` or `sgd` that will take the list of parameters and update them based on their gradients.\n",
    "* Don't forget to `.zero_()` the gradients after each udpate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8194616b-dd7c-4da5-9341-9fb017b24968",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1dde49d765d7cb187ce0e61a7e6e19f",
     "grade": false,
     "grade_id": "Q1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def forward(x, W1, b1, W2, b2):\n",
    "    \"\"\"Complete a forward pass through the network for input x.\"\"\"\n",
    "    \n",
    "\n",
    "\n",
    "# Code for training the network.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a53a5a-f50f-49cf-8713-0f90b5558b41",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ace9a41fde4d056cc5193588188c5343",
     "grade": true,
     "grade_id": "cell-a5bb2aa60d446b50",
     "locked": true,
     "points": 9,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Testing Code\n",
    "\n",
    "test_size = 1000\n",
    "X_test, y_test = noisy_xor(test_size)\n",
    "X_test = torch.tensor(X_test)\n",
    "y_test = torch.tensor(y_test)\n",
    "\n",
    "correct = 0\n",
    "for i in range(test_size):\n",
    "    if torch.round(y_test[i, 0]) == torch.round(forward(X_test[i, :], W1, b1, W2, b2)):\n",
    "        correct += 1\n",
    "\n",
    "print(\"ACCURACY\", correct / test_size)\n",
    "assert correct / test_size > .9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3319b1ca-b044-4f8f-85a6-e2d7c5280e5f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0e5796b96e2ef9f9713049c5709dafd8",
     "grade": false,
     "grade_id": "cell-67e56642b6cdc5bc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Visualize the Decision Boundary\n",
    "\n",
    "Once you are satisfied with your results, execute the following cell to visualize the decision boundary learned by your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7359aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the decision boundary (Code Produced by Claude Sonnet 4)\n",
    "\n",
    "def plot_decision_boundary(X, y, W1, b1, W2, b2):\n",
    "    \"\"\"Plot the decision boundary learned by the network.\"\"\"\n",
    "    # Create a mesh grid\n",
    "    h = 0.02  # step size in the mesh\n",
    "    x_min, x_max = X[:, 0].min().item() - 0.1, X[:, 0].max().item() + 0.1\n",
    "    y_min, y_max = X[:, 1].min().item() - 0.1, X[:, 1].max().item() + 0.1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    \n",
    "    # Make predictions on the mesh grid\n",
    "    grid_points = torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        Z = []\n",
    "        for point in grid_points:\n",
    "            pred = forward(point, W1, b1, W2, b2)\n",
    "            Z.append(pred.item())\n",
    "        Z = np.array(Z)\n",
    "    \n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot the decision boundary\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.contourf(xx, yy, Z, levels=50, alpha=0.8, cmap=plt.cm.RdYlBu)\n",
    "    plt.colorbar(label='Network Output')\n",
    "    \n",
    "    # Plot the training data\n",
    "    plt.scatter(X[y[:, 0] == 1, 0], X[y[:, 0] == 1, 1], c='red', marker='s', s=100, edgecolors='black', label='Class 1')\n",
    "    plt.scatter(X[y[:, 0] == 0, 0], X[y[:, 0] == 0, 1], c='blue', marker='o', s=100, edgecolors='black', label='Class 0')\n",
    "    \n",
    "    # Add decision boundary contour\n",
    "    plt.contour(xx, yy, Z, levels=[0.5], colors='black', linestyles='--', linewidths=2)\n",
    "    \n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.title('MLP Decision Boundary for XOR Problem')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Plot the decision boundary\n",
    "plot_decision_boundary(X, y, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe1c520-49d5-4302-a260-a52cdbedb715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
